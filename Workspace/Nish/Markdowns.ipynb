{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our audience in this case is the Hulu Technology Team headed by the CTO of Hulu. They are holding a competition to upgrade their current machine learning algorithm that oversees the movie recommendations given to a Hulu user/consumer. Our task was to build a model that provides top 5 movie recommendations to a user, based on their ratings of other movies. Currently, Hulu uses a item-based collaborative filtering algorithm, this is a successful approach commonly used by many recommender systems, it takes into consideration the ratings given to items by users as the sole source of information for learning to make recommendation. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set that we used is from MovieLens, it contains 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business question is How can our model be used to provide 5 recommendations to a user based on a Collaborative filtering? We also have a sub questions : What are the top 10 movie recommendations for a given genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise was the main library we used to produce our collaborative filtering model.This library has endogenous methods of splitting our data set, cross validating, performing grid searches as well various different algorithms that can be used to build recommendation systems. As you go through this notebook, you will see that we had to use a combination of both surprise and scikit-learn methods to ensure the successful deployment of model. Since the syntax of surprise and sklearn are similar, this made this process much more efficient, it also ensures that the notebook would be readable to anyone with a background in data science. We mainly utilized surprise to transform the data set to a suitable data format that can be used in recommendation systems. We also employed pickling to make loading onto any new computer an easier process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
